{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyg/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/wyg/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/wyg/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/wyg/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/wyg/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/wyg/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/wyg/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/wyg/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/wyg/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/wyg/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/wyg/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/wyg/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ReLU  \n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "from tensorflow.contrib.quantize import experimental_create_training_graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入数据\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wyg/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# 建立模型\n",
    "input_tensor = Input(shape=(28, 28, 1), name='input_tensor')\n",
    "# 第一层\n",
    "x = Conv2D(32, (3, 3), name='conv1')(input_tensor)\n",
    "x = ReLU(name='relu1')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), name='maxpool1')(x)\n",
    "## 第二层\n",
    "x = Conv2D(64, (3, 3), name='conv2')(x)\n",
    "x = ReLU(name='relu2')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), name='maxpool2')(x)\n",
    "# 第三层\n",
    "x = Conv2D(128, (3, 3), name='conv3')(x)\n",
    "x = ReLU(name='relu3')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2), name='maxpool3')(x)\n",
    "# 输出层\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(128)(x)\n",
    "x = ReLU(name='reluout')(x)\n",
    "\n",
    "output_tensor = Dense(10, name='output_tensor')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#记录每个训练模型中的所有变量。\n",
    "#准备恢复每个训练模型的权重。\n",
    "#导致下一步重写中添加的变量get\n",
    "#添加到全局变量集合中，\n",
    "#我们需要在重写图形之前进行记录\n",
    "per_trained_model_path = './models/float_point/model.ckpt'\n",
    "restore_dict = {}\n",
    "reader = tf.train.NewCheckpointReader(per_trained_model_path)\n",
    "for v in tf.global_variables():\n",
    "    tensor_name = v.name.split(':')[0]\n",
    "    if reader.has_tensor(tensor_name):\n",
    "        restore_dict[tensor_name] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重写图，向训练图添加伪量化操作\n",
    "experimental_create_training_graph(input_graph=sess.graph, \n",
    "                                   weight_bits=8, \n",
    "                                   activation_bits=8)\n",
    "\n",
    "# 当添加伪量化操作时，我们添加了很多变量\n",
    "# 所以我们必须初始化变量\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wyg/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./models/float_point/model.ckpt\n",
      "node name: conv1/weights_quant/AssignMinLast\n",
      "node name: conv1/weights_quant/AssignMaxLast\n",
      "node name: conv2/weights_quant/AssignMinLast\n",
      "node name: conv2/weights_quant/AssignMaxLast\n",
      "node name: conv3/weights_quant/AssignMinLast\n",
      "node name: conv3/weights_quant/AssignMaxLast\n",
      "node name: dense/weights_quant/AssignMinLast\n",
      "node name: dense/weights_quant/AssignMaxLast\n",
      "node name: output_tensor/weights_quant/AssignMinLast\n",
      "node name: output_tensor/weights_quant/AssignMaxLast\n"
     ]
    }
   ],
   "source": [
    "# 恢复包含在每个训练模型中的变量\n",
    "saver = tf.train.Saver(restore_dict)\n",
    "saver.restore(sess, per_trained_model_path)\n",
    "\n",
    "# 检查是否成功添加了伪量化操作\n",
    "for node in sess.graph.as_graph_def().node:\n",
    "    if 'AssignMaxLast' in node.name or 'AssignMinLast' in node.name:\n",
    "        print('node name: {}'.format(node.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模型。 通常，我们在加载时会使用较小的学习率 \n",
    "# 已经训练好的浮点模型 \n",
    "model.compile(loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.8432933586120606\n",
      "Test accuracy: 0.103\n"
     ]
    }
   ],
   "source": [
    "#评估伪造量化操作添加模型的性能\n",
    "#在量化意识训练开始之前\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#创建一个tensorboard回调以查看重写图的详细信息\n",
    "#模型编号。 例如，在conv1范围内，我们可以找到act_quant\n",
    "#子图，其中包含有关量化的信息，例如最小和最大。\n",
    "tensorboard = TensorBoard('logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 65s 1ms/sample - loss: 1.6822 - acc: 0.4962 - val_loss: 0.5351 - val_acc: 0.8850\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 62s 1ms/sample - loss: 0.3093 - acc: 0.9186 - val_loss: 0.1875 - val_acc: 0.9443\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 56s 931us/sample - loss: 0.1712 - acc: 0.9488 - val_loss: 0.1374 - val_acc: 0.9562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3ce047d7d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ＃开始量化感知训练\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=3,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1373714783065021\n",
      "Test accuracy: 0.9562\n"
     ]
    }
   ],
   "source": [
    "# 评估量化意识训练模型的性能\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/quant_aware_trained/model.ckpt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save quantize-aware trained model to checkpoint file\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, './models/quant_aware_trained/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
